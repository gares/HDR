@inproceedings{Michaylov1993HigherOrderLP,
  title={Higher-Order Logic Programming as Constraint Logic Programming},
  author={Spiro Michaylov and Frank Pfenning},
  booktitle={Principles and Practice of Constraint Programming},
  year={1993},
  url={https://api.semanticscholar.org/CorpusID:9980455}
}
@book{Miller_Nadathur_2012, place={Cambridge}, title={Programming with Higher-Order Logic}, publisher={Cambridge University Press}, author={Miller, Dale and Nadathur, Gopalan}, year={2012}}
@book{ridoux1998lambda,
  title={Lambda-Prolog de A {\`a} Z... ou presque},
  author={Ridoux, O.},
  publisher="Habilitation à diriger des recherches",
  url={https://books.google.fr/books?id=XFhGXwAACAAJ},
  year={1998}
}
@InProceedings{sakaguchi:LIPIcs.ITP.2022.29,
  author =	{Sakaguchi, Kazuhiko},
  title =	{{Reflexive Tactics for Algebra, Revisited}},
  booktitle =	{13th International Conference on Interactive Theorem Proving (ITP 2022)},
  pages =	{29:1--29:22},
  series =	{Leibniz International Proceedings in Informatics (LIPIcs)},
  ISBN =	{978-3-95977-252-5},
  ISSN =	{1868-8969},
  year =	{2022},
  volume =	{237},
  editor =	{Andronick, June and de Moura, Leonardo},
  publisher =	{Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.ITP.2022.29},
  URN =		{urn:nbn:de:0030-drops-167385},
  doi =		{10.4230/LIPIcs.ITP.2022.29},
  annote =	{Keywords: Coq, Elpi, \lambdaProlog, Mathematical Components, algebraic structures, packed classes, canonical structures, proof by reflection}
}
@InProceedings{10.1007/978-3-031-57262-3_10,
author="Cohen, Cyril
and Crance, Enzo
and Mahboubi, Assia",
editor="Weirich, Stephanie",
title="Trocq: Proof Transfer for Free, With or Without Univalence",
booktitle="Programming Languages and Systems",
year="2024",
publisher="Springer Nature Switzerland",
address="Cham",
pages="239--268",
abstract="This article presents Trocq, a new proof transfer framework for dependent type theory. Trocq is based on a novel formulation of type equivalence, used to generalize the univalent parametricity translation. This framework takes care of avoiding dependency on the axiom of univalence when possible, and may be used with more relations than just equivalences. We have implemented a corresponding plugin for the Coq interactive theorem prover, in the Coq-Elpi meta-language.",
isbn="978-3-031-57262-3"
}


@book{Jojgov,
title = "Systems for open terms : an overview",
author = "G.I. Jojgov",
year = "2001",
language = "English",
series = "Computer science reports",
publisher = "Technische Universiteit Eindhoven",

}

@article{miller92jsc,
  author =       "Dale Miller",
  title =        "Unification under a mixed prefix",
  year =         "1992",
  journal =      "Journal of Symbolic Computation",
  pages =        "321--358",
  volume =       "14",
  number =       "4",
  doi =          "10.1016/0747-7171(92)90011-R",
  pdf =          "http://www.lix.polytechnique.fr/Labo/Dale.Miller/papers/jsc92.pdf",
}

@misc{Coq-refman,
  title = "The {Rooq} Reference Manual -- Release 9.0.0",
  author = "{The Rocq Development Team}",
  year = "2025",
  howpublished = "\url{https://rocq-prover.org/doc/V9.0.0/refman/index.html}"
}
@inproceedings{dealmeidaborges_et_al:LIPIcs.ITP.2023.12,
  author =	{de Almeida Borges, Ana and Casanueva Art{\'\i}s, Annal{\'\i} and Falleri, Jean-R\'{e}my and Gallego Arias, Emilio Jes\'{u}s and Martin-Dorel, \'{E}rik and Palmskog, Karl and Serebrenik, Alexander and Zimmermann, Th\'{e}o},
  title =	{{Lessons for Interactive Theorem Proving Researchers from a Survey of Coq Users}},
  booktitle =	{14th International Conference on Interactive Theorem Proving (ITP 2023)},
  pages =	{12:1--12:18},
  series =	{Leibniz International Proceedings in Informatics (LIPIcs)},
  ISBN =	{978-3-95977-284-6},
  ISSN =	{1868-8969},
  year =	{2023},
  volume =	{268},
  editor =	{Naumowicz, Adam and Thiemann, Ren\'{e}},
  publisher =	{Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.ITP.2023.12},
  URN =		{urn:nbn:de:0030-drops-183875},
  doi =		{10.4230/LIPIcs.ITP.2023.12},
  annote =	{Keywords: Coq, Community, Survey, Statistical Analysis}
}
@inproceedings{DBLP:conf/cpp/Blot0CPKMV23,
  author       = {Valentin Blot and
                  Denis Cousineau and
                  Enzo Crance and
                  Louise Dubois de Prisque and
                  Chantal Keller and
                  Assia Mahboubi and
                  Pierre Vial},
  editor       = {Robbert Krebbers and
                  Dmitriy Traytel and
                  Brigitte Pientka and
                  Steve Zdancewic},
  title        = {Compositional Pre-processing for Automated Reasoning in Dependent
                  Type Theory},
  booktitle    = {Proceedings of the 12th {ACM} {SIGPLAN} International Conference on
                  Certified Programs and Proofs, {CPP} 2023, Boston, MA, USA, January
                  16-17, 2023},
  pages        = {63--77},
  publisher    = {{ACM}},
  year         = {2023},
  url          = {https://doi.org/10.1145/3573105.3575676},
  doi          = {10.1145/3573105.3575676},
  timestamp    = {Tue, 07 Mar 2023 15:01:48 +0100},
  biburl       = {https://dblp.org/rec/conf/cpp/Blot0CPKMV23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@book{10.5555/1200583,
author = {Ierusalimschy, Roberto},
title = {Programming in Lua, Second Edition},
year = {2006},
isbn = {8590379825},
publisher = {Lua.Org}
}

@InProceedings{10.1007/978-3-540-27775-0_7,
author="Duck, Gregory J.
and Stuckey, Peter J.
and de la Banda, Mar{\'i}a Garc{\'i}a
and Holzbaur, Christian",
editor="Demoen, Bart
and Lifschitz, Vladimir",
title="The Refined Operational Semantics of Constraint Handling Rules",
booktitle="Logic Programming",
year="2004",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="90--104",
abstract="Constraint Handling Rules (CHRs) are a high-level rule-based programming language commonly used to write constraint solvers. The theoretical operational semantics for CHRs is highly non-deterministic and relies on writing confluent programs to have a meaningful behaviour. Implementations of CHRs use an operational semantics which is considerably finer than the theoretical operational semantics, but is still non-deterministic (from the user's perspective). This paper formally defines this refined operational semantics and proves it implements the theoretical operational semantics. It also shows how to create a (partial) confluence checker capable of detecting programs which are confluent under this semantics, but not under the theoretical operational semantics. This supports the use of new idioms in CHR programs.",
isbn="978-3-540-27775-0"
}
@article{chr, title={As time goes by: Constraint Handling Rules: A survey of CHR research from 1998 to 2007}, volume={10}, DOI={10.1017/S1471068409990123}, number={1}, journal={Theory and Practice of Logic Programming}, author={SNEYERS, JON and VAN WEERT, PETER and SCHRIJVERS, TOM and DE KONINCK, LESLIE}, year={2010}, pages={1–47}}


@InProceedings{keller_et_al:LIPIcs.CSL.2012.381,
  author =	{Keller, Chantal and Lasson, Marc},
  title =	{{Parametricity in an Impredicative Sort}},
  booktitle =	{Computer Science Logic (CSL'12) - 26th International Workshop/21st Annual Conference of the EACSL},
  pages =	{381--395},
  series =	{Leibniz International Proceedings in Informatics (LIPIcs)},
  ISBN =	{978-3-939897-42-2},
  ISSN =	{1868-8969},
  year =	{2012},
  volume =	{16},
  editor =	{C\'{e}gielski, Patrick and Durand, Arnaud},
  publisher =	{Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CSL.2012.381},
  URN =		{urn:nbn:de:0030-drops-36851},
  doi =		{10.4230/LIPIcs.CSL.2012.381},
  annote =	{Keywords: Calculus of Inductive Constructions, parametricity, impredicativity, Coq, universes}
}

@misc{selsam2020tabledtypeclassresolution,
      title={Tabled Typeclass Resolution}, 
      author={Daniel Selsam and Sebastian Ullrich and Leonardo de Moura},
      year={2020},
      eprint={2001.04301},
      archivePrefix={arXiv},
      primaryClass={cs.PL},
      url={https://arxiv.org/abs/2001.04301}, 
}
@article{MILNER1978348,
title = {A theory of type polymorphism in programming},
journal = {Journal of Computer and System Sciences},
volume = {17},
number = {3},
pages = {348-375},
year = {1978},
issn = {0022-0000},
doi = {https://doi.org/10.1016/0022-0000(78)90014-4},
url = {https://www.sciencedirect.com/science/article/pii/0022000078900144},
author = {Robin Milner},
abstract = {The aim of this work is largely a practical one. A widely employed style of programming, particularly in structure-processing languages which impose no discipline of types, entails defining procedures which work well on objects of a wide variety. We present a formal type discipline for such polymorphic procedures in the context of a simple programming language, and a compile time type-checking algorithm W which enforces the discipline. A Semantic Soundness Theorem (based on a formal semantics for the language) states that well-type programs cannot “go wrong” and a Syntactic Soundness Theorem states that if W accepts a program then it is well typed. We also discuss extending these results to richer languages; a type-checking algorithm based on W is in fact already implemented and working, for the metalanguage ML in the Edinburgh LCF system.}
}

@article{NADATHUR200235,
title = {The Suspension Notation for Lambda Terms and its Use in Metalanguage Implementations},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {67},
pages = {35-48},
year = {2002},
note = {WoLLIC'2002, 9th Workhop on Logic, Language, Information and Computation},
issn = {1571-0661},
doi = {https://doi.org/10.1016/S1571-0661(04)80539-5},
url = {https://www.sciencedirect.com/science/article/pii/S1571066104805395},
author = {Gopalan Nadathur},
keywords = {logical framework, explicit substitution, suspension notation},
abstract = {Many metalanguages and logical frameworks have emerged in recent years that use the terms of the lambda calculus as data structures. A common set of questions govern the suitability of a representation for lambda terms in the implementation of such systems: α-convertibility must be easily recognizable, sharing in reduction steps, term traversal and term structure must be possible, comparison and unification operations should be efficiently supported and it should be possible to examine terms embedded inside abstractions. Explicit substitution notations for lambda calculi provide a basis for realizing such requirements. We discuss here the issues related to using one such notation—the suspension notation of Nadathur and Wilson—in this capacity. This notation has been used in two significant practical systems: the Standard ML of New Jersey compiler and the Teyjus implementation of λ-Prolog. We expose the theoretical properties of this notation, highlight pragmatic considerations in its use in implementing operations such as reduction and unification and discuss its relationship to other explicit substitution notations.}
}

@article{10.1145/3236788,
author = {Stampoulis, Antonis and Chlipala, Adam},
title = {Prototyping a functional language using higher-order logic programming: a functional pearl on learning the ways of $\lambda$Prolog/Makam},
year = {2018},
issue_date = {September 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {ICFP},
url = {https://doi.org/10.1145/3236788},
doi = {10.1145/3236788},
journal = {Proc. ACM Program. Lang.},
month = jul,
articleno = {93},
numpages = {30},
keywords = {programming language prototyping, metaprogramming, higher-order logic programming}
}

@article{10.1145/3429979,
author = {Tabareau, Nicolas and Tanter, \'{E}ric and Sozeau, Matthieu},
title = {The Marriage of Univalence and Parametricity},
year = {2021},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {68},
number = {1},
issn = {0004-5411},
url = {https://doi.org/10.1145/3429979},
doi = {10.1145/3429979},
abstract = {Reasoning modulo equivalences is natural for everyone, including mathematicians. Unfortunately, in proof assistants based on type theory, which are frequently used to mechanize mathematical results and carry out program verification efforts, equality is appallingly syntactic, and as a result, exploiting equivalences is cumbersome at best. Parametricity and univalence are two major concepts that have been explored in the literature to transport programs and proofs across type equivalences, but they fall short of achieving seamless, automatic transport. This work first clarifies the limitations of these two concepts when considered in isolation and then devises a fruitful marriage between both. The resulting concept, called univalent parametricity, is an extension of parametricity strengthened with univalence that fully realizes programming and proving modulo equivalences. Our approach handles both type and term dependency, as well as type-level computation. In addition to the theory of univalent parametricity, we present a lightweight framework implemented in the Coq proof assistant that allows the user to transparently transfer definitions and theorems for a type to an equivalent one, as if they were equal. For instance, this makes it possible to conveniently switch between an easy-to-reason-about representation and a computationally efficient representation as soon as they are proven equivalent. The combination of parametricity and univalence supports transport \`{a} la carte: basic univalent transport, which stems from a type equivalence, can be complemented with additional proofs of equivalences between functions over these types, in order to be able to transport more programs and proofs, as well as to yield more efficient terms. We illustrate the use of univalent parametricity on several examples, including a recent integration of native integers in Coq. This work paves the way to easier-to-use proof assistants by supporting seamless programming and proving modulo equivalences.},
journal = {J. ACM},
month = jan,
articleno = {5},
numpages = {44},
keywords = {Coq, Type equivalence, parametricity, proof assistants, univalence}
}

@phdthesis{enzo,
  title        = {Meta-Programming for Proof Transfer in Dependent Type Theory},
  author       = {Enzo Crance},
  year         = 2023,
  month        = {December},
  address      = {Nantes},
  note         = {Available at \url{https://ecrance.net/files/thesis-Enzo-Crance-en-light.pdf}},
  school       = {University of Nantes},
  type         = {PhD thesis}
}

@phdthesis{mcbride,
  author       = {Conor McBride},
  title        = {Dependently typed functional programs and their proofs},
  school       = {University of Edinburgh, {UK}},
  year         = {2000},
  url          = {https://hdl.handle.net/1842/374},
  timestamp    = {Wed, 04 May 2022 12:59:24 +0200},
  biburl       = {https://dblp.org/rec/phd/ethos/McBride00.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@article{Miller2018MechanizedMR,
  title={Mechanized Metatheory Revisited},
  author={Dale A. Miller},
  journal={Journal of Automated Reasoning},
  year={2018},
  volume={63},
  pages={625 - 665},
  url={https://api.semanticscholar.org/CorpusID:8571809}
}

@inproceedings{mlts,
author = {G\'{e}rard, Ulysse and Miller, Dale and Scherer, Gabriel},
title = {Functional programming with λ-tree syntax},
year = {2019},
isbn = {9781450372497},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3354166.3354177},
doi = {10.1145/3354166.3354177},
abstract = {We present the design of a new functional programming language, MLTS, that uses the λ-tree syntax approach to encoding bindings appearing within data structures. In this approach, bindings never become free nor escape their scope: instead, binders in data structures are permitted to move to binders within programs. The design of MLTS includes additional sites within programs that directly support this movement of bindings. In order to formally define the language's operational semantics, we present an abstract syntax for MLTS and a natural semantics for its evaluation. We shall view such natural semantics as a logical theory within a rich logic that includes both nominal abstraction and the ∇-quantifier: as a result, the natural semantics specification of MLTS can be given a succinct and elegant presentation. We present a typing discipline that naturally extends the typing of core ML programs and we illustrate the features of MLTS by presenting several examples. An on-line interpreter for MLTS is briefly described.},
booktitle = {Proceedings of the 21st International Symposium on Principles and Practice of Declarative Programming},
articleno = {12},
numpages = {16},
location = {Porto, Portugal},
series = {PPDP '19}
}

@INPROCEEDINGS{abella,
  author = {Andrew Gacek},
  title = {The {A}bella Interactive Theorem Prover (System
                  Description)},
  year = 2008,
  month = {August},
  booktitle = {Proceedings of IJCAR 2008},
  pages = {154--161},
  publisher = {Springer},
  series = {Lecture Notes in Artificial Intelligence},
  volume = 5195,
  editor = {A. Armando and P. Baumgartner and G. Dowek},
  pdf = {http://arxiv.org/pdf/0803.2305.pdf},
  slides = {http://abella-prover.org/slides/gacek08ijcar-slides.pdf}
}
@inproceedings{logicT,
author = {Kiselyov, Oleg and Shan, Chung-chieh and Friedman, Daniel P. and Sabry, Amr},
title = {Backtracking, interleaving, and terminating monad transformers: (functional pearl)},
year = {2005},
isbn = {1595930647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1086365.1086390},
doi = {10.1145/1086365.1086390},
abstract = {We design and implement a library for adding backtracking computations to any Haskell monad. Inspired by logic programming, our library provides, in addition to the operations required by the MonadPlus interface, constructs for fair disjunctions, fair conjunctions, conditionals, pruning, and an expressive top-level interface. Implementing these additional constructs is easy in models of backtracking based on streams, but not known to be possible in continuation-based models. We show that all these additional constructs can be generically and monadically realized using a single primitive msplit. We present two implementations of the library: one using success and failure continuations; and the other using control operators for manipulating delimited continuations.},
booktitle = {Proceedings of the Tenth ACM SIGPLAN International Conference on Functional Programming},
pages = {192–203},
numpages = {12},
keywords = {streams, logic programming, control delimiters, continuations, Prolog, Haskell},
location = {Tallinn, Estonia},
series = {ICFP '05}
}
@InProceedings{fctc,
author="Sozeau, Matthieu
and Oury, Nicolas",
editor="Mohamed, Otmane Ait
and Mu{\~{n}}oz, C{\'e}sar
and Tahar, Sofi{\`e}ne",
title="First-Class Type Classes",
booktitle="Theorem Proving in Higher Order Logics",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="278--293",
abstract="Type Classes have met a large success in Haskell and Isabelle, as a solution for sharing notations by overloading and for specifying with abstract structures by quantification on contexts. However, both systems are limited by second-class implementations of these constructs, and these limitations are only overcomed by ad-hoc extensions to the respective systems. We propose an embedding of type classes into a dependent type theory that is first-class and supports some of the most popular extensions right away. The implementation is correspondingly cheap, general and integrates well inside the system, as we have experimented in Coq. We show how it can be used to help structured programming and proving by way of examples.",
isbn="978-3-540-71067-7"
}
@InProceedings{brigittePHD,
author="Pientka, Brigitte",
editor="Nieuwenhuis, Robert",
title="Tabling for Higher-Order Logic Programming",
booktitle="Automated Deduction -- CADE-20",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="54--68",
abstract="We describe the design and implementation of a higher-order tabled logic programming interpreter where some redundant and infinite computation is eliminated by memoizing sub-computation and re-using its result later. In particular, we focus on the table design and table access in the higher-order setting where many common operations are undecidable in general. To achieve a space and time efficient implementation, we rely on substitution factoring and higher-order substitution tree indexing. Experimental results from a wide range of examples (propositional theorem proving, refinement type checking, small-step evaluator) demonstrate that higher-order tabled logic programming yields a more robust and more powerful proof procedure.",
isbn="978-3-540-31864-4"
}
@article{expsubst, title={Explicit substitutions}, volume={1}, DOI={10.1017/S0956796800000186}, number={4}, journal={Journal of Functional Programming}, author={Abadi, M. and Cardelli, L. and Curien, P.-L. and Lévy, J.-J.}, year={1991}, pages={375–416}}

@incollection{DEBRUIJN1994375,
title = {Lambda Calculus Notation with Nameless Dummies, a Tool for Automatic Formula Manipulation, with Application to the Church-Rosser Theorem**Reprinted from: Indagationes Math, 34, 5, p. 381-392, by courtesy of the Koninklijke Nederlandse Akademie van Wetenschappen, Amsterdam.},
editor = {R.P. Nederpelt and J.H. Geuvers and R.C. {de Vrijer}},
series = {Studies in Logic and the Foundations of Mathematics},
publisher = {Elsevier},
volume = {133},
pages = {375-388},
year = {1994},
booktitle = {Selected Papers on Automath},
issn = {0049-237X},
doi = {https://doi.org/10.1016/S0049-237X(08)70216-7},
url = {https://www.sciencedirect.com/science/article/pii/S0049237X08702167},
author = {N.G. de Bruijn},
abstract = {In ordinary lambda calculus the occurrences of a bound variable are made recognizable by the use of one and the same (otherwise irrelevant) name at all occurrences. This convention is known to cause considerable trouble in cases of substitution. In the present paper a different notational system is developed, where occurrences of variables are indicated by integers giving the “distance” to the binding λ instead of a name attached to that λ. The system is claimed to be efficient for automatic formula manipulation as well as for metalingual discussion. As an example the most essential part of a proof of the Church-Rosser theorem is presented in this namefree calculus.}
}

@book{wam,
    author = {Aït-Kaci, Hassan},
    title = {Warren's Abstract Machine: A Tutorial Reconstruction},
    publisher = {The MIT Press},
    year = {1991},
    month = {08},
    abstract = {This tutorial demystifies one of the most important yet poorly understood aspects of logic programming, the Warren Abstract Machine or WAM. The author's step-by-step construction of the WAM adds features in a gradual manner, clarifying the complex aspects of the design and providing the first detailed study of WAM since it was designed in 1983. Developed by David H. D. Warren, the WAM is an abstract (nonphysical) computer that aids in the compilation and implementation of the Prolog programming language and offers techniques for compiling and optimizing symbolic computing that can be generalized beyond Prolog. Although the benefits of the WAM design have been widely accepted, few have been able to penetrate the WAM. This lucid introduction defines separate abstract machines for each conceptually separate part of the design and refines them, finally stitching them together to make a WAM. An index presents all of the critical concepts used in the WAM. It is assumed that readers have a clear understanding of the operational semantics of Prolog, in particular, of unification and backtracking, but a brief summary of the necessary Prolog notions is provided.Contents Introduction • Unification—Pure and Simple • Flat Resolution • Prolog • Optimizing the Design • Conclusion • Appendixes},
    isbn = {9780262255585},
    doi = {10.7551/mitpress/7160.001.0001},
    url = {https://doi.org/10.7551/mitpress/7160.001.0001},
}

@inproceedings{teyjus,
author = {Nadathur, Gopalan and Mitchell, Dustin J.},
title = {System Description: Teyjus - A Compiler and Abstract Machine Based Implementation of lambda-Prolog},
year = {1999},
isbn = {3540662227},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The logic programming language λProlog is based on the intuitionistic theory of higher-order hereditary Harrop formulas, a logic that significantly extends the theory of Horn clauses. A systematic exploitation of features in the richer logic endows λProlog with capabilities at the programming level that are not present in traditional logic programming languages. Several studies have established the value of λProlog as a language for implementing systems that manipulate formal objects such as formulas, programs, proofs and types. Towards harnessing these benefits, methods have been developed for realizing this language efficiently. This work has culminated in the description of an abstract machine and compiler based implementation scheme. An actual implementation of λProlog based on these ideas has recently been completed. The planned presentation will exhibit this system--called Teyjus--and will also illuminate the metalanguage capabilities of λProlog.},
booktitle = {Proceedings of the 16th International Conference on Automated Deduction: Automated Deduction},
pages = {287–291},
numpages = {5},
series = {CADE-16}
}

@article{DBLP:journals/corr/abs-0911-5203,
  author       = {Xiaochu Qi},
  title        = {An Implementation of the Language Lambda Prolog Organized around Higher-Order
                  Pattern Unification},
  journal      = {CoRR},
  volume       = {abs/0911.5203},
  year         = {2009},
  url          = {http://arxiv.org/abs/0911.5203},
  eprinttype    = {arXiv},
  eprint       = {0911.5203},
  timestamp    = {Mon, 13 Aug 2018 16:48:41 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-0911-5203.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@InProceedings{10.1007/978-3-540-45085-6_40,
author="Pientka, Brigitte and Pfenning, Frank",
editor="Baader, Franz",
title="Optimizing Higher-Order Pattern Unification",
booktitle="Automated Deduction -- CADE-19",
year="2003",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="473--487",
abstract="We present an abstract view of existential variables in a dependently typed lambda-calculus based on modal type theory. This allows us to justify optimizations to pattern unification such as linearization, which eliminates many unnecessary occurs-checks. The presented modal framework explains a number of features of the current implementation of higher-order unification in Twelf and provides insight into several optimizations. Experimental results demonstrate significant performance improvement in many example applications of Twelf, including those in the area of proof-carrying code.",
isbn="978-3-540-45085-6"
}

@article{10.1093/logcom/1.4.497,
    author = {MILLER, DALE},
    title = {A Logic Programming Language with Lambda-Abstraction, Function Variables, and Simple Unification},
    journal = {Journal of Logic and Computation},
    volume = {1},
    number = {4},
    pages = {497-536},
    year = {1991},
    month = {09},
    abstract = {It has been argued elsewhere that a logic programming language with function variables and λ-abstractions within terms makes a good meta-programming language, especially when an object-language contains notions of bound variables and scope. The λProlog logic programming language and the related Elf and Isabelle systems provide meta-programs with both function variables and λ-abstractions by containing implementations of higher order unification. This paper presents a logic programming language, called Lλ, that also contains both function variables and λ-abstractions, although certain restrictions are placed on occurrences of function variables. As a result of these restrictions, an implementation of Lλdoes not need to implement full higher-order unification. Instead, an extension to first-order unification that respects bound variable names and scopes is all that is required. Such unification problems are shown to be decidable and to possess most general unifiers when unifiers exist. A unification algorithm and logic programming interpreter are described and proved correct. Several examples of using Lλ as a meta-programming language are presented.},
    issn = {0955-792X},
    doi = {10.1093/logcom/1.4.497},
    url = {https://doi.org/10.1093/logcom/1.4.497},
    eprint = {https://academic.oup.com/logcom/article-pdf/1/4/497/3817142/1-4-497.pdf},
}


@inproceedings{Okasaki:98:IntMap,
  author = {Chris Okasaki and Andy Gill},
  title = {Fast mergeable integer maps},
  pages = {77--86},
  booktitle = {ACM SIGPLAN Workshop on ML},
  year = {1998},
  month = {September},
}

@techreport{10.5555/868728,
author = {Nadathur, Gopalan and Pfenning, Frank},
title = {The Type System of a Higher-Order Logic Programming Language},
year = {1992},
publisher = {Duke University},
address = {USA},
abstract = {The type system of the logic programming language $lambda$Prolog is discussed. The incorporation of higher-order notions within this language requires the use of a typing scheme to distinguish between expressions of different function types. Thus $lambda$Prolog is a (strongly) typed language, in contrast to the typeless language that underlies the idea of descriptive types in logic programming. The typing discipline that is employed in the language is based on the notion of simple types in the $lambda$-calculus. This form of typing enforces arity restrictions on functions and predicates and provides a builtin functional hierarchy over terms. The language contains a facility for defining new primitive types and thus permits finer grained distinctions to be introduced by the user. Further, the use of type variables and type constructors provides a form of polymorphism that is similar in certain respects to that present in the language ML. The notion of type checking in $lambda$Prolog is discussed and shown to be an operation that can be performed at the time of compilation. The value of typing distinctions in determining the clarity of programs and their usefulness in conjunction with type checking in preventing run-time errors due to type violations is also discussed. In addition to their function in type checking, types also have a major role in determining computations in the logic programming context. We discuss this aspect of types that is in contrast to their behavior in other programming paradigms and we show how this leads to a presence of types in the runtime environment. While typing has several advantages, it is sometimes to the programmer''s advantage to be able to omit their mention. Type reconstruction provides a means for filling missing type information in and we discuss issues pertinent to this process in the context of $lambda$Prolog.}
}
@InProceedings{10.1007/978-3-642-03359-9_4,
author="Harrison, John",
editor="Berghofer, Stefan
and Nipkow, Tobias
and Urban, Christian
and Wenzel, Makarius",
title="HOL Light: An Overview",
booktitle="Theorem Proving in Higher Order Logics",
year="2009",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="60--66",
abstract="HOL Light is an interactive proof assistant for classical higher-order logic, intended as a clean and simplified version of Mike Gordon's original HOL system. Theorem provers in this family use a version of ML as both the implementation and interaction language; in HOL Light's case this is Objective CAML (OCaml). Thanks to its adherence to the so-called `LCF approach', the system can be extended with new inference rules without compromising soundness. While retaining this reliability and programmability from earlier HOL systems, HOL Light is distinguished by its clean and simple design and extremely small logical kernel. Despite this, it provides powerful proof tools and has been applied to some non-trivial tasks in the formalization of mathematics and industrial formal verification.",
isbn="978-3-642-03359-9"
}
@inproceedings{10.1145/141471.141563,
author = {Sabry, Amr and Felleisen, Matthias},
title = {Reasoning about programs in continuation-passing style.},
year = {1992},
isbn = {0897914813},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/141471.141563},
doi = {10.1145/141471.141563},
abstract = {Plotkin's λ-value calculus is sound but incomplete for reasoning about βeegr;-transformations on programs in continuation-passing style (CPS).  To find a complete extension, we define a new, compactifying CPS transformation and an “inverse”mapping, un-CPS, both of which are interesting in their own right.   Using the new CPS transformation, we can determine the precise language of CPS terms closed under β7eegr;-transformations. Using the un-CPS transformation, we can derive a set of axioms such that every equation between source programs is provable if and only if βη can prove the corresponding equation between CPS programs.  The extended calculus is equivalent to an untyped variant of Moggi's computational λ-calculus.},
booktitle = {Proceedings of the 1992 ACM Conference on LISP and Functional Programming},
pages = {288–298},
numpages = {11},
location = {San Francisco, California, USA},
series = {LFP '92}
}

@article{10.1145/141478.141563,
author = {Sabry, Amr and Felleisen, Matthias},
title = {Reasoning about programs in continuation-passing style.},
year = {1992},
issue_date = {Jan. 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {V},
number = {1},
issn = {1045-3563},
url = {https://doi.org/10.1145/141478.141563},
doi = {10.1145/141478.141563},
abstract = {Plotkin's λ-value calculus is sound but incomplete for reasoning about βeegr;-transformations on programs in continuation-passing style (CPS).  To find a complete extension, we define a new, compactifying CPS transformation and an “inverse”mapping, un-CPS, both of which are interesting in their own right.   Using the new CPS transformation, we can determine the precise language of CPS terms closed under β7eegr;-transformations. Using the un-CPS transformation, we can derive a set of axioms such that every equation between source programs is provable if and only if βη can prove the corresponding equation between CPS programs.  The extended calculus is equivalent to an untyped variant of Moggi's computational λ-calculus.},
journal = {SIGPLAN Lisp Pointers},
month = jan,
pages = {288–298},
numpages = {11}
}


@inproceedings{chaudhuri:hal-01806154,
  TITLE = {{Computation-as-deduction in Abella: work in progress}},
  AUTHOR = {Chaudhuri, Kaustuv and G{\'e}rard, Ulysse and Miller, Dale},
  URL = {https://inria.hal.science/hal-01806154},
  BOOKTITLE = {{13th international Workshop on Logical Frameworks and Meta-Languages: Theory and Practice}},
  ADDRESS = {Oxford, United Kingdom},
  YEAR = {2018},
  MONTH = Jul,
  PDF = {https://inria.hal.science/hal-01806154v1/file/paper.pdf},
  HAL_ID = {hal-01806154},
  HAL_VERSION = {v1},
}

@inproceedings{HarperHP87,
  title = {A Framework for Defining Logics},
  author = {Robert Harper and Furio Honsell and Gordon D. Plotkin},
  year = {1987},
  tags = {logic},
  researchr = {https://researchr.org/publication/HarperHP87},
  cites = {0},
  citedby = {0},
  pages = {194-204},
  booktitle = {Proceedings, Symposium on Logic in Computer Science, 22-25 June 1987, Ithaca, New York, USA},
  publisher = {IEEE Computer Society},
}
@article{SHEARD200849,
title = {Meta-programming With Built-in Type Equality},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {199},
pages = {49-65},
year = {2008},
note = {Proceedings of the Fourth International Workshop on Logical Frameworks and Meta-Languages (LFM 2004)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2007.11.012},
url = {https://www.sciencedirect.com/science/article/pii/S1571066108000789},
author = {Tim Sheard and Emir Pasalic},
keywords = {Meta-programming, Meta-language, Equality types},
abstract = {We report our experience with exploring a new point in the design space for formal reasoning systems: the development of the programming language Ωmega. Ωmega is intended as both a practical programming language and a logic. The main goal of Ωmega is to allow programmers to describe and reason about semantic properties of programs from within the programming language itself, mainly by using a powerful type system. We illustrate the main features of Ωmega by developing an interesting meta-programming example. First, we show how to encode a set of well-typed simply typed λ-calculus terms as an Ωmega data-type. Then, we show how to implement a substitution operation on these terms that is guaranteed by the Ωmega type system to preserve their well-typedness.}
}
@article{10.1145/2775051.2676980,
author = {Jung, Ralf and Swasey, David and Sieczkowski, Filip and Svendsen, Kasper and Turon, Aaron and Birkedal, Lars and Dreyer, Derek},
title = {Iris: Monoids and Invariants as an Orthogonal Basis for Concurrent Reasoning},
year = {2015},
issue_date = {January 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {1},
issn = {0362-1340},
url = {https://doi.org/10.1145/2775051.2676980},
doi = {10.1145/2775051.2676980},
abstract = {We present Iris, a concurrent separation logic with a simple premise: monoids and invariants are all you need. Partial commutative monoids enable us to express---and invariants enable us to enforce---user-defined *protocols* on shared state, which are at the conceptual core of most recent program logics for concurrency. Furthermore, through a novel extension of the concept of a *view shift*, Iris supports the encoding of *logically atomic specifications*, i.e., Hoare-style specs that permit the client of an operation to treat the operation essentially as if it were atomic, even if it is not.},
journal = {SIGPLAN Not.},
month = jan,
pages = {637–650},
numpages = {14},
keywords = {separation logic, partial commutative monoids, invariants, higher-order logic, fine-grained concurrency, compositional verification, atomicity}
}

@inproceedings{10.1145/2676726.2676980,
author = {Jung, Ralf and Swasey, David and Sieczkowski, Filip and Svendsen, Kasper and Turon, Aaron and Birkedal, Lars and Dreyer, Derek},
title = {Iris: Monoids and Invariants as an Orthogonal Basis for Concurrent Reasoning},
year = {2015},
isbn = {9781450333009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2676726.2676980},
doi = {10.1145/2676726.2676980},
abstract = {We present Iris, a concurrent separation logic with a simple premise: monoids and invariants are all you need. Partial commutative monoids enable us to express---and invariants enable us to enforce---user-defined *protocols* on shared state, which are at the conceptual core of most recent program logics for concurrency. Furthermore, through a novel extension of the concept of a *view shift*, Iris supports the encoding of *logically atomic specifications*, i.e., Hoare-style specs that permit the client of an operation to treat the operation essentially as if it were atomic, even if it is not.},
booktitle = {Proceedings of the 42nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
pages = {637–650},
numpages = {14},
keywords = {separation logic, partial commutative monoids, invariants, higher-order logic, fine-grained concurrency, compositional verification, atomicity},
location = {Mumbai, India},
series = {POPL '15}
}

@inproceedings{10.1007/978-3-662-54434-1_26,
author = {Krebbers, Robbert and Jung, Ralf and Bizjak, Ale\v{s} and Jourdan, Jacques-Henri and Dreyer, Derek and Birkedal, Lars},
title = {The Essence of Higher-Order Concurrent Separation Logic},
year = {2017},
isbn = {978-3-662-54433-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-662-54434-1_26},
doi = {10.1007/978-3-662-54434-1_26},
abstract = {Concurrent separation logics (CSLs) have come of age, and with age they have accumulated a great deal of complexity. Previous work on the Iris logic attempted to reduce the complex logical mechanisms of modern CSLs to two orthogonal concepts: partial commutative monoids (PCMs) and invariants. However, the realization of these concepts in Iris still bakes in several complex mechanisms—such as weakest preconditions and mask-changing view shifts—as primitive notions.In this paper, we take the Iris story to its (so to speak) logical conclusion, applying the reductionist methodology of Iris to Iris itself. Specifically, we define a small, resourceful base logic, which distills the essence of Iris: it comprises only the assertion layer of vanilla separation logic, plus a handful of simple modalities. We then show how the much fancier logical mechanisms of Iris—in particular, its entire program specification layer—can be understood as merely derived forms in our base logic. This approach helps to explain the meaning of Iris’s program specifications at a much higher level of abstraction than was previously possible. We also show that the step-indexed “later” modality of Iris is an essential source of complexity, in that removing it leads to a logical inconsistency. All our results are fully formalized in the Coq proof assistant.},
booktitle = {Programming Languages and Systems: 26th European Symposium on Programming, ESOP 2017, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2017, Uppsala, Sweden, April 22–29, 2017, Proceedings},
pages = {696–723},
numpages = {28},
location = {Uppsala, Sweden}
}

@phdthesis{rob,
  title        = {Applications of Foundational Proof Certificates in theorem proving},
  author       = {Roberto Blanco},
  year         = 2017,
  month        = {December},
  address      = {Paris},
  note         = {Available at \url{https://theses.fr/2017SACLX111}},
  school       = {École polytechnique, Université Paris-Saclay},
  type         = {PhD thesis}
}

@inproceedings{matteo,
  TITLE = {{FPC-Coq: using ELPI to elaborate external proof evidence into Coq proofs (system description)}},
  AUTHOR = {Roberto Blanco, Matteo Manighetti and Dale Miller},
  BOOKTITLE = {{Coq Workshop 2020}},
  YEAR = {2020},
  MONTH = Jul,
}

@inproceedings{alberto,
  author       = {Matteo Manighetti and
                  Dale Miller and
                  Alberto Momigliano},
  editor       = {Ugo de'Liguoro and
                  Stefano Berardi and
                  Thorsten Altenkirch},
  title        = {Two Applications of Logic Programming to Coq},
  booktitle    = {26th International Conference on Types for Proofs and Programs, {TYPES}
                  2020, March 2-5, 2020, University of Turin, Italy},
  series       = {LIPIcs},
  volume       = {188},
  pages        = {10:1--10:19},
  publisher    = {Schloss Dagstuhl - Leibniz-Zentrum f{\"{u}}r Informatik},
  year         = {2020},
  url          = {https://doi.org/10.4230/LIPIcs.TYPES.2020.10},
  doi          = {10.4230/LIPICS.TYPES.2020.10},
  timestamp    = {Wed, 21 Aug 2024 22:46:00 +0200},
  biburl       = {https://dblp.org/rec/conf/types/Manighetti0M20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@article{Marek_2016, title={All about Proofs, Proofs for All, Bruno Woltzenlogel Paleoand David Delahaye , Eds., College Publications, Series Mathematical Logic and Foundations, vol. 55., 2015. Paperback, ISBN 978-1-84890-166-7, vii + 240 pages.}, volume={16}, DOI={10.1017/S1471068415000125}, number={2}, journal={Theory and Practice of Logic Programming}, author={Marek, Victor W.}, year={2016}, pages={236–241}}

@article{RABE20131,
title = {A scalable module system},
journal = {Information and Computation},
volume = {230},
pages = {1-54},
year = {2013},
issn = {0890-5401},
doi = {https://doi.org/10.1016/j.ic.2013.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S0890540113000631},
author = {Florian Rabe and Michael Kohlhase},
abstract = {Symbolic and logic computation systems ranging from computer algebra systems to theorem provers are finding their way into science, technology, mathematics and engineering. But such systems rely on explicitly or implicitly represented mathematical knowledge that needs to be managed to use such systems effectively. While mathematical knowledge management (MKM) “in the small” is well-studied, scaling up to large, highly interconnected corpora remains difficult. We hold that in order to realize MKM “in the large”, we need representation languages and software architectures that are designed systematically with large-scale processing in mind. Therefore, we have designed and implemented the Mmt language – a module system for mathematical theories. Mmt is designed as the simplest possible language that combines a module system, a foundationally uncommitted formal semantics, and web-scalable implementations. Due to a careful choice of representational primitives, Mmt allows us to integrate existing representation languages for formal mathematical knowledge in a simple, scalable formalism. In particular, Mmt abstracts from the underlying mathematical and logical foundations so that it can serve as a standardized representation format for a formal digital library. Moreover, Mmt systematically separates logic-dependent and logic-independent concerns so that it can serve as an interface layer between computation systems and MKM systems.}
}

@inproceedings{10.1007/978-3-642-12251-4_1,
author = {Pientka, Brigitte},
title = {Beluga: programming with dependent types, contextual data, and contexts},
year = {2010},
isbn = {3642122507},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-12251-4_1},
doi = {10.1007/978-3-642-12251-4_1},
abstract = {The logical framework LF provides an elegant foundation for specifying formal systems and proofs and it is used successfully in a wide range of applications such as certifying code and mechanizing meta-theory of programming languages. However, incorporating LF technology into functional programming to allow programmers to specify and reason about formal guarantees of their programs from within the programming language itself has been a major challenge.In this paper, we present an overview of Beluga, a framework for programming and reasoning with formal systems. It supports specifying formal systems in LF and it also provides a dependently typed functional language that supports analyzing and manipulating LF data via pattern matching. A distinct feature of Beluga is its direct support for reasoning with contexts and contextual objects. Taken together these features lead to a powerful language which supports writing compact and elegant proofs.},
booktitle = {Proceedings of the 10th International Conference on Functional and Logic Programming},
pages = {1–12},
numpages = {12},
location = {Sendai, Japan},
series = {FLOPS'10}
}
@inproceedings{DBLP:conf/cade/PientkaC15,
  author       = {Brigitte Pientka and
                  Andrew Cave},
  editor       = {Amy P. Felty and
                  Aart Middeldorp},
  title        = {Inductive Beluga: Programming Proofs},
  booktitle    = {Automated Deduction - {CADE-25} - 25th International Conference on
                  Automated Deduction, Berlin, Germany, August 1-7, 2015, Proceedings},
  series       = {Lecture Notes in Computer Science},
  volume       = {9195},
  pages        = {272--281},
  publisher    = {Springer},
  year         = {2015},
  url          = {https://doi.org/10.1007/978-3-319-21401-6\_18},
  doi          = {10.1007/978-3-319-21401-6\_18},
  timestamp    = {Tue, 14 May 2019 10:00:39 +0200},
  biburl       = {https://dblp.org/rec/conf/cade/PientkaC15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{https://doi.org/10.1112/blms/22.1.101,
author = {Johnstone, P. T.},
title = {TOPOSES AND LOCAL SET THEORIES: AN INTRODUCTION (Oxford Logic Guides 14)},
journal = {Bulletin of the London Mathematical Society},
volume = {22},
number = {1},
pages = {101-102},
doi = {https://doi.org/10.1112/blms/22.1.101},
url = {https://londmathsoc.onlinelibrary.wiley.com/doi/abs/10.1112/blms/22.1.101},
eprint = {https://londmathsoc.onlinelibrary.wiley.com/doi/pdf/10.1112/blms/22.1.101},
abstract = {By J. L. Bell: pp. 267. £35.00. (Oxford University Press, 1988)},
year = {1990}
}

@InProceedings{10.1007/11532231_5,
author="Pientka, Brigitte",
editor="Nieuwenhuis, Robert",
title="Tabling for Higher-Order Logic Programming",
booktitle="Automated Deduction -- CADE-20",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="54--68",
abstract="We describe the design and implementation of a higher-order tabled logic programming interpreter where some redundant and infinite computation is eliminated by memoizing sub-computation and re-using its result later. In particular, we focus on the table design and table access in the higher-order setting where many common operations are undecidable in general. To achieve a space and time efficient implementation, we rely on substitution factoring and higher-order substitution tree indexing. Experimental results from a wide range of examples (propositional theorem proving, refinement type checking, small-step evaluator) demonstrate that higher-order tabled logic programming yields a more robust and more powerful proof procedure.",
isbn="978-3-540-31864-4"
}

@inproceedings{10.1145/191839.191927,
author = {Sagonas, Konstantinos and Swift, Terrance and Warren, David S.},
title = {XSB as an efficient deductive database engine},
year = {1994},
isbn = {0897916395},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191839.191927},
doi = {10.1145/191839.191927},
abstract = {This paper describes the XSB system, and its use as an in-memory deductive database engine. XSB began from a Prolog foundation, and traditional Prolog systems are known to have serious deficiencies when used as database systems. Accordingly, XSB has a fundamental bottom-up extension, introduced through tabling (or memoing)[4], which makes it appropriate as an underlying query engine for deductive database systems. Because it eliminates redundant computation, the tabling extension makes XSB able to compute all modularly stratified datalog programs finitely and with polynomial data complexity. For non-stratified programs, a meta-interpreter with the same properties is provided. In addition XSB significantly extends and improves the indexing capabilities over those of standard Prolog.  Finally, its syntactic basis in HiLog [2], lends it flexibility for data modelling.The implementation of XSB derives from the WAM [25], the most common Prolog engine. XSB inherits the WAM's efficiency and can take advantage of extensive compiler technology developed for Prolog. As a result, performance comparisons indicate that XSB is significantly faster than other deductive database systems for a wide range of queries and stratified rule sets. XSB is under continuous development, and version 1.3 is available through anonymous ftp.},
booktitle = {Proceedings of the 1994 ACM SIGMOD International Conference on Management of Data},
pages = {442–453},
numpages = {12},
location = {Minneapolis, Minnesota, USA},
series = {SIGMOD '94}
}

@article{prolog, title={Fifty Years of Prolog and Beyond}, volume={22}, DOI={10.1017/S1471068422000102}, number={6}, journal={Theory and Practice of Logic Programming}, author={KÖRNER, PHILIPP and LEUSCHEL, MICHAEL and BARBOSA, JOÃO and COSTA, VÍTOR SANTOS and DAHL, VERÓNICA and HERMENEGILDO, MANUEL V. and MORALES, JOSE F. and WIELEMAKER, JAN and DIAZ, DANIEL and ABREU, SALVADOR and et al.}, year={2022}, pages={776–858}}

@book{prolog0,
title = "La naissance de Prolog",
author = "Alain Colmerauer et Philippe Roussel",
year = "1992",
url = "http://alain.colmerauer.free.fr/alcol/ArchivesPublications/PrologHistoire/24juillet92plus/24juillet92plusvar.pdf",
}

@article{FRUHWIRTH199895,
title = {Theory and practice of constraint handling rules},
journal = {The Journal of Logic Programming},
volume = {37},
number = {1},
pages = {95-138},
year = {1998},
issn = {0743-1066},
doi = {https://doi.org/10.1016/S0743-1066(98)10005-5},
url = {https://www.sciencedirect.com/science/article/pii/S0743106698100055},
author = {Thom Frühwirth},
abstract = {Constraint Handling Rules (CHR) are our proposal to allow more flexibility and application-oriented customization of constraint systems. CHR are a declarative language extension especially designed for writing user-defined constraints. CHR are essentially a committed-choice language consisting of multi-headed guarded rules that rewrite constraints into simpler ones until they are solved. In this broad survey we aim at covering all aspects of CHR as they currently present themselves. Going from theory to practice, we will define syntax and semantics for CHR, introduce an important decidable property, confluence, of CHR programs and define a tight integration of CHR with constraint logic programming languages. This survey then describes implementations of the language before we review several constraint solvers – both traditional and nonstandard ones – written in the CHR language. Finally we introduce two innovative applications that benefited from using CHR.}
}

@inproceedings{1989Vink,
  author    = {de Bruin, A.
               and de Vink, E. P.},
  editor    = {D{\'i}az, Josep
               and Orejas, Fernando},
  title     = {Continuation semantics for PROLOG with cut},
  booktitle = {TAPSOFT '89},
  year      = {1989},
  publisher = {Springer},
  xaddress   = {Berlin, Heidelberg},
  pages     = {178--192},
  abstract  = {We present a denotational continuation semantics for PROLOG with cut. First a uniform language ℬ is studied, which captures the control flow aspects of PROLOG. The denotational seman
tics for ℬ is proven equivalent to a transition system based operational semantics. The congruence proof relies on the representation of the operational semantics as a chain of approximations and o
n a convenient induction principle. Finally, we interpret the abstract language ℬ such that we obtain equivalent denotational and operational models for PROLOG itself.},
  isbn      = {978-3-540-46116-6}
}
@article{Church1940AFO,
  title={A formulation of the simple theory of types},
  author={Alonzo Church},
  journal={Journal of Symbolic Logic},
  year={1940},
  volume={5},
  pages={56 - 68},
  url={https://api.semanticscholar.org/CorpusID:15889861}
}

@inproceedings{10.1145/53990.54010,
author = {Pfenning, F. and Elliott, C.},
title = {Higher-order abstract syntax},
year = {1988},
isbn = {0897912691},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/53990.54010},
doi = {10.1145/53990.54010},
abstract = {We describe motivation, design, use, and implementation of higher-order abstract syntax as a central representation for programs, formulas, rules, and other syntactic objects in program manipulation and other formal systems where matching and substitution or unification are central operations. Higher-order abstract syntax incorporates name binding information in a uniform and language generic way. Thus it acts as a powerful link integrating diverse tools in such formal environments. We have implemented higher-order abstract syntax, a supporting matching and unification algorithm, and some clients in Common Lisp in the framework of the Ergo project at Carnegie Mellon University.},
booktitle = {Proceedings of the ACM SIGPLAN 1988 Conference on Programming Language Design and Implementation},
pages = {199–208},
numpages = {10},
location = {Atlanta, Georgia, USA},
series = {PLDI '88}
}

@article{10.1145/960116.54010,
author = {Pfenning, F. and Elliott, C.},
title = {Higher-order abstract syntax},
year = {1988},
issue_date = {July 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {7},
issn = {0362-1340},
url = {https://doi.org/10.1145/960116.54010},
doi = {10.1145/960116.54010},
abstract = {We describe motivation, design, use, and implementation of higher-order abstract syntax as a central representation for programs, formulas, rules, and other syntactic objects in program manipulation and other formal systems where matching and substitution or unification are central operations. Higher-order abstract syntax incorporates name binding information in a uniform and language generic way. Thus it acts as a powerful link integrating diverse tools in such formal environments. We have implemented higher-order abstract syntax, a supporting matching and unification algorithm, and some clients in Common Lisp in the framework of the Ergo project at Carnegie Mellon University.},
journal = {SIGPLAN Not.},
month = jun,
pages = {199–208},
numpages = {10}
}

@book{10.7551/mitpress/2319.001.0001,
    author = {Milner, Robin and Harper, Robert and MacQueen, David and Tofte, Mads},
    title = {The Definition of Standard ML},
    publisher = {The MIT Press},
    year = {1997},
    month = {05},
    abstract = {Standard ML is a general-purpose programming language designed for large projects. This book provides a formal definition of Standard ML for the benefit of all concerned with the language, including users and implementers. Because computer programs are increasingly required to withstand rigorous analysis, it is all the more important that the language in which they are written be defined with full rigor. One purpose of a language definition is to establish a theory of meanings upon which the understanding of particular programs may rest. To properly define a programming language, it is necessary to use some form of notation other than a programming language. Given a concern for rigor, mathematical notation is an obvious choice. The authors have defined their semantic objects in mathematical notation that is completely independent of Standard ML. In defining a language one must also define the rules of evaluation precisely—that is, define what meaning results from evaluating any phrase of the language. The definition thus constitutes a formal specification for an implementation. The authors have developed enough of their theory to give sense to their rules of evaluation. The Definition of Standard ML is the essential point of reference for Standard ML. Since its publication in 1990, the implementation technology of the language has advanced enormously and the number of users has grown. The revised edition includes a number of new features, omits little-used features, and corrects mistakes of definition.},
    isbn = {9780262287005},
    doi = {10.7551/mitpress/2319.001.0001},
    url = {https://doi.org/10.7551/mitpress/2319.001.0001},
}

@mastersthesis{Maas2024,
  author      = {Luko van der Maas},
  title       = {Extending the {I}ris {P}roof {M}ode with Inductive Predicates using {E}lpi},
  school      = {Radboud University Nijmegen},
  doi         = {10.5281/zenodo.12568604},
  year        = {2024}
}

@article{10.1145/321250.321253,
author = {Robinson, J. A.},
title = {A Machine-Oriented Logic Based on the Resolution Principle},
year = {1965},
issue_date = {Jan. 1965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {1},
issn = {0004-5411},
url = {https://doi.org/10.1145/321250.321253},
doi = {10.1145/321250.321253},
journal = {J. ACM},
month = jan,
pages = {23–41},
numpages = {19}
}